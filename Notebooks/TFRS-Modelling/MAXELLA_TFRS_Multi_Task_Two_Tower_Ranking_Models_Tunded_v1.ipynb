{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab2989f",
   "metadata": {},
   "source": [
    "# MAXELLA TFRS: Multi-Task Model - Joint Model\n",
    "\n",
    "## The Two-Tower and Ranking Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859153c",
   "metadata": {},
   "source": [
    "## Contents \n",
    "\n",
    "\n",
    " * Introduction\n",
    " * Dataset\n",
    " * Sourcing and Loading\n",
    " * A Multi-Task Model\n",
    "   * Rating-specialized Model\n",
    "   * Retrieval-specialized Model\n",
    "   * Joint Model\n",
    " * Modeling Summary\n",
    " * Next Step - Joint Model Tuning\n",
    "   * Adding more features\n",
    "   * Optimize Embedding\n",
    "   * embedding_dimension 32 to 64\n",
    "   * epochs= 3 to 32\n",
    "   * Learning rate\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc786173",
   "metadata": {},
   "source": [
    "## 1. Introduction \n",
    "\n",
    "In the [TFRS Modeling - Two-Tower](https://github.com/akthammomani/MAXELLA-APP-Movies-Tensorflow-Recommenders-TFRS/tree/main/Notebooks/TFRS-Modelling) we built a retrieval system using movie watches as positive interaction signals.\n",
    "\n",
    "In many applications, however, there are multiple rich sources of feedback to draw upon. For example, an e-commerce site may record user visits to product pages (abundant, but relatively low signal), image clicks, adding to cart, and, finally, purchases. It may even record post-purchase signals such as reviews and returns.\n",
    "\n",
    "Integrating all these different forms of feedback is critical to building systems that users love to use, and that do not optimize for any one metric at the expense of overall performance.\n",
    "\n",
    "In addition, building a joint model for multiple tasks may produce better results than building a number of task-specific models. This is especially true where some data is abundant (for example, clicks), and some data is sparse (purchases, returns, manual reviews). In those scenarios, a joint model may be able to use representations learned from the abundant task to improve its predictions on the sparse task via a phenomenon known as [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning). For example, [this paper](https://openreview.net/pdf?id=SJxPVcSonN) shows that a model predicting explicit user ratings from sparse user surveys can be substantially improved by adding an auxiliary task that uses abundant click log data.\n",
    "\n",
    "In this Notebook, we are going to build a multi-objective recommender for Movielens, using both implicit (movie watches) and explicit signals (ratings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e78703",
   "metadata": {},
   "source": [
    "## 2. Dataset: \n",
    "\n",
    "**Movie Lens** contains a set of movie ratings from the MovieLens website, a movie recommendation service. This dataset was collected and maintained by [GroupLens](https://grouplens.org/) , a research group at the University of Minnesota. There are 5 versions included: \"25m\", \"latest-small\", \"100k\", \"1m\", \"20m\". In all datasets, the movies data and ratings data are joined on \"movieId\". The 25m dataset, latest-small dataset, and 20m dataset contain only movie data and rating data. The 1m dataset and 100k dataset contain demographic data in addition to movie and rating data.\n",
    "\n",
    "**movie_lens/1m** can be treated in two ways:\n",
    "\n",
    "  * It can be interpreted as expressesing which movies the users watched (and rated), and which they did not. This is a form of *implicit feedback*, where users' watches tell us which things they prefer to see and which they'd rather not see (This means that every movie a user watched is a positive example, and every movie they have not seen is an implicit negative example).\n",
    "  * It can also be seen as expressesing how much the users liked the movies they did watch. This is a form of *explicit feedback*: given that a user watched a movie, we can tell roughly how much they liked by looking at the rating they have given.\n",
    "\n",
    "\n",
    "\n",
    "**(a) [movie_lens/1m-ratings](https://www.tensorflow.org/datasets/catalog/movie_lens#movie_lens1m-ratings):**\n",
    " * Config description: This dataset contains 1,000,085 anonymous ratings of approximately 3,619 movies made by 6,040 MovieLens users who joined MovieLens. Ratings are in whole-star increments. This dataset contains demographic data of users in addition to data on movies and ratings.\n",
    " * This dataset is the largest dataset that includes demographic data from movie_lens.\n",
    " * \"user_gender\": gender of the user who made the rating; a true value corresponds to male\n",
    " * \"bucketized_user_age\": bucketized age values of the user who made the rating, the values and the corresponding ranges are:\n",
    "   * 1: \"Under 18\"\n",
    "   * 18: \"18-24\"\n",
    "   * 25: \"25-34\"\n",
    "   * 35: \"35-44\"\n",
    "   * 45: \"45-49\"\n",
    "   * 50: \"50-55\"\n",
    "   * 56: \"56+\"\n",
    " * \"user_occupation_label\": the occupation of the user who made the rating represented by an integer-encoded label; labels are preprocessed to be consistent across different versions\n",
    " * \"user_occupation_text\": the occupation of the user who made the rating in the original string; different versions can have different set of raw text labels\n",
    " * \"user_zip_code\": the zip code of the user who made the rating.\n",
    " * \"release_date\": This is the movie release date, in unix epoch (UTC - units of seconds) (int64).\n",
    " * \"director\": This is the director of the movie.\n",
    " * \"start\": This is the main star of the movie.\n",
    " \n",
    " **(b) [movie_lens/1m-movies](https://www.tensorflow.org/datasets/catalog/movie_lens#movie_lens1m-movies):**\n",
    "\n",
    " * Config description: This dataset contains data of approximately 3,619 movies rated in the 1m dataset.\n",
    " * Download size: 5.64 MiB\n",
    " * Dataset size: 351.12 KiB\n",
    " * Auto-cached ([documentation](https://www.tensorflow.org/datasets/performances#auto-caching)): Yes\n",
    " * Features:\n",
    "```\n",
    "FeaturesDict({\n",
    "              'movie_genres': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=21)),\n",
    "              'movie_id': tf.string,\n",
    "              'movie_title': tf.string,\n",
    "             })\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c9aa4",
   "metadata": {},
   "source": [
    "## 3. Sourcing and Loading\n",
    "\n",
    "### 3.1 Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce3e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary Libararies: \n",
    "\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfdsZ\n",
    "from typing import Dict, Text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50156f6d",
   "metadata": {},
   "source": [
    "### 3.2 Preparing the dataset\n",
    "\n",
    "Let's first have a look at the data.\n",
    "\n",
    "We use the MovieLens dataset from Tensorflow Datasets. Loading **[movie_lens/1m-ratings](https://www.tensorflow.org/datasets/catalog/movie_lens#movie_lens1m-ratings)** yields a ***tf.data.Dataset*** object containing the ratings data and loading **[movie_lens/1m-movies](https://www.tensorflow.org/datasets/catalog/movie_lens#movie_lens1m-movies)** yields a ***tf.data.Dataset*** object containing only the movies data.\n",
    "\n",
    "Note that since the MovieLens dataset does not have predefined splits, all data are under train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c08762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's look at the final dataframe where we merged tensorflow dataset with movies_metadata.csv and credits.csv**\n",
    "# let's make sure to use encoding argument to avoid in encoding errors !!!\n",
    "ratings = pd.read_csv('ratings.csv', encoding='ISO-8859-1')\n",
    "movies = pd.read_csv('movies.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f47358d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_occupation_label</th>\n",
       "      <th>user_occupation_text</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_zip_code</th>\n",
       "      <th>director</th>\n",
       "      <th>release_date</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>[7]</td>\n",
       "      <td>1251</td>\n",
       "      <td>Eight and half</td>\n",
       "      <td>974089380</td>\n",
       "      <td>False</td>\n",
       "      <td>2497</td>\n",
       "      <td>14</td>\n",
       "      <td>sales/marketing</td>\n",
       "      <td>3</td>\n",
       "      <td>37922</td>\n",
       "      <td>Federico Fellini</td>\n",
       "      <td>-217123200</td>\n",
       "      <td>Marcello Mastroianni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>[7]</td>\n",
       "      <td>1251</td>\n",
       "      <td>Eight and half</td>\n",
       "      <td>986722200</td>\n",
       "      <td>True</td>\n",
       "      <td>671</td>\n",
       "      <td>17</td>\n",
       "      <td>college/grad student</td>\n",
       "      <td>5</td>\n",
       "      <td>61761</td>\n",
       "      <td>Federico Fellini</td>\n",
       "      <td>-217123200</td>\n",
       "      <td>Marcello Mastroianni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>[7]</td>\n",
       "      <td>1251</td>\n",
       "      <td>Eight and half</td>\n",
       "      <td>960071880</td>\n",
       "      <td>False</td>\n",
       "      <td>5590</td>\n",
       "      <td>12</td>\n",
       "      <td>programmer</td>\n",
       "      <td>2</td>\n",
       "      <td>94117</td>\n",
       "      <td>Federico Fellini</td>\n",
       "      <td>-217123200</td>\n",
       "      <td>Marcello Mastroianni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>[7]</td>\n",
       "      <td>1251</td>\n",
       "      <td>Eight and half</td>\n",
       "      <td>1011993120</td>\n",
       "      <td>True</td>\n",
       "      <td>1851</td>\n",
       "      <td>20</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>5</td>\n",
       "      <td>59602</td>\n",
       "      <td>Federico Fellini</td>\n",
       "      <td>-217123200</td>\n",
       "      <td>Marcello Mastroianni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>[7]</td>\n",
       "      <td>1251</td>\n",
       "      <td>Eight and half</td>\n",
       "      <td>963100320</td>\n",
       "      <td>False</td>\n",
       "      <td>5526</td>\n",
       "      <td>1</td>\n",
       "      <td>artist</td>\n",
       "      <td>5</td>\n",
       "      <td>27514</td>\n",
       "      <td>Federico Fellini</td>\n",
       "      <td>-217123200</td>\n",
       "      <td>Marcello Mastroianni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucketized_user_age movie_genres  movie_id      movie_title   timestamp  \\\n",
       "0                   50          [7]      1251  Eight and half    974089380   \n",
       "1                   18          [7]      1251  Eight and half    986722200   \n",
       "2                   45          [7]      1251  Eight and half    960071880   \n",
       "3                   25          [7]      1251  Eight and half   1011993120   \n",
       "4                   35          [7]      1251  Eight and half    963100320   \n",
       "\n",
       "   user_gender  user_id  user_occupation_label  user_occupation_text  \\\n",
       "0        False     2497                     14       sales/marketing   \n",
       "1         True      671                     17  college/grad student   \n",
       "2        False     5590                     12            programmer   \n",
       "3         True     1851                     20            unemployed   \n",
       "4        False     5526                      1                artist   \n",
       "\n",
       "   user_rating  user_zip_code          director  release_date  \\\n",
       "0            3          37922  Federico Fellini    -217123200   \n",
       "1            5          61761  Federico Fellini    -217123200   \n",
       "2            2          94117  Federico Fellini    -217123200   \n",
       "3            5          59602  Federico Fellini    -217123200   \n",
       "4            5          27514  Federico Fellini    -217123200   \n",
       "\n",
       "                   star  \n",
       "0  Marcello Mastroianni  \n",
       "1  Marcello Mastroianni  \n",
       "2  Marcello Mastroianni  \n",
       "3  Marcello Mastroianni  \n",
       "4  Marcello Mastroianni  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's look at the new features we added: 'movie_imdb_id', 'cast', 'director', 'cast_size', 'crew_size', 'imdb_id' and 'release_date':\n",
    "#Also, please note that all wrong spelled movies are corrected!!!!\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e9c258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7]</td>\n",
       "      <td>1251</td>\n",
       "      <td>Eight and half</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[7]</td>\n",
       "      <td>2188</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7]</td>\n",
       "      <td>1609</td>\n",
       "      <td>One Eight Seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[13, 15]</td>\n",
       "      <td>2311</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>2031</td>\n",
       "      <td>The Million Dollar Duck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_genres  movie_id              movie_title\n",
       "0          [7]      1251          Eight and half \n",
       "1          [7]      2188                       54\n",
       "2          [7]      1609          One Eight Seven\n",
       "3     [13, 15]      2311                     2010\n",
       "4       [3, 4]      2031  The Million Dollar Duck"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's look at the new features we added: 'movie_imdb_id', 'cast', 'director', 'cast_size', 'crew_size', 'imdb_id' and 'release_date':\n",
    "#Also, please note that all wrong spelled movies are corrected!!!!\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3713752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000085 entries, 0 to 1000084\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count    Dtype \n",
      "---  ------                 --------------    ----- \n",
      " 0   bucketized_user_age    1000085 non-null  int64 \n",
      " 1   movie_genres           1000085 non-null  object\n",
      " 2   movie_id               1000085 non-null  int64 \n",
      " 3   movie_title            1000085 non-null  object\n",
      " 4   timestamp              1000085 non-null  int64 \n",
      " 5   user_gender            1000085 non-null  bool  \n",
      " 6   user_id                1000085 non-null  int64 \n",
      " 7   user_occupation_label  1000085 non-null  int64 \n",
      " 8   user_occupation_text   1000085 non-null  object\n",
      " 9   user_rating            1000085 non-null  int64 \n",
      " 10  user_zip_code          1000085 non-null  int64 \n",
      " 11  director               1000085 non-null  object\n",
      " 12  release_date           1000085 non-null  int64 \n",
      " 13  star                   1000085 non-null  object\n",
      "dtypes: bool(1), int64(8), object(5)\n",
      "memory usage: 100.1+ MB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2fe9165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3658 entries, 0 to 3657\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   movie_genres  3658 non-null   object\n",
      " 1   movie_id      3658 non-null   int64 \n",
      " 2   movie_title   3658 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 85.9+ KB\n"
     ]
    }
   ],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20cd6a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_id from int to str:\n",
    "ratings['movie_id'] = ratings['movie_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c8b1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_id from int to str:\n",
    "movies['movie_id'] = movies['movie_id'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0379b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id from int to str:\n",
    "ratings['user_id'] = ratings['user_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56379ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_zip_code from int to str:\n",
    "ratings['user_zip_code'] = ratings['user_zip_code'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e739014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_id from int to str:\n",
    "ratings['bucketized_user_age'] = ratings['bucketized_user_age'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ab74380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_id from int to str:\n",
    "ratings['timestamp'] = ratings['timestamp'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e28027d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_id from int to str:\n",
    "ratings['release_date'] = ratings['release_date'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "558ba6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_id from int to str:\n",
    "ratings['user_rating'] = ratings['user_rating'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f5e8383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>data_type</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <td>7</td>\n",
       "      <td>float32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_genres</th>\n",
       "      <td>302</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <td>3656</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_title</th>\n",
       "      <td>3619</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <td>165897</td>\n",
       "      <td>float32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_gender</th>\n",
       "      <td>2</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>6040</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_occupation_label</th>\n",
       "      <td>21</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_occupation_text</th>\n",
       "      <td>21</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rating</th>\n",
       "      <td>5</td>\n",
       "      <td>float32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_zip_code</th>\n",
       "      <td>3402</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director</th>\n",
       "      <td>1845</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release_date</th>\n",
       "      <td>2411</td>\n",
       "      <td>float32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star</th>\n",
       "      <td>1840</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count data_type missing_count missing%\n",
       "bucketized_user_age         7   float32             0      0.0\n",
       "movie_genres              302    object             0      0.0\n",
       "movie_id                 3656    object             0      0.0\n",
       "movie_title              3619    object             0      0.0\n",
       "timestamp              165897   float32             0      0.0\n",
       "user_gender                 2      bool             0      0.0\n",
       "user_id                  6040    object             0      0.0\n",
       "user_occupation_label      21     int64             0      0.0\n",
       "user_occupation_text       21    object             0      0.0\n",
       "user_rating                 5   float32             0      0.0\n",
       "user_zip_code            3402    object             0      0.0\n",
       "director                 1845    object             0      0.0\n",
       "release_date             2411   float32             0      0.0\n",
       "star                     1840    object             0      0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a general view of main_df:\n",
    "ratings_missing = pd.concat([ratings.nunique(), ratings.dtypes, ratings.isnull().sum(), 100*ratings.isnull().mean()], axis=1)\n",
    "ratings_missing.columns = [['count', 'data_type', 'missing_count', 'missing%']]\n",
    "ratings_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6a05ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>data_type</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie_genres</th>\n",
       "      <td>302</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <td>3656</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_title</th>\n",
       "      <td>3619</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count data_type missing_count missing%\n",
       "movie_genres   302    object             0      0.0\n",
       "movie_id      3656    object             0      0.0\n",
       "movie_title   3619    object             0      0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a general view of main_df:\n",
    "movies_missing = pd.concat([movies.nunique(), movies.dtypes, movies.isnull().sum(), 100*movies.isnull().mean()], axis=1)\n",
    "movies_missing.columns = [['count', 'data_type', 'missing_count', 'missing%']]\n",
    "movies_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46d5cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's wrap the **pandas dataframe** into **tf.data.Dataset** object using **tf.data.Dataset.from_tensor_slices** using: tf.data.Dataset.from_tensor_slices\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings))\n",
    "movies = tf.data.Dataset.from_tensor_slices(dict(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ae5062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 50.0,\n",
      " 'director': b'Federico Fellini',\n",
      " 'movie_genres': b'[7]',\n",
      " 'movie_id': b'1251',\n",
      " 'movie_title': b'Eight and half ',\n",
      " 'release_date': -217123200.0,\n",
      " 'star': b'Marcello Mastroianni',\n",
      " 'timestamp': 974089400.0,\n",
      " 'user_gender': False,\n",
      " 'user_id': b'2497',\n",
      " 'user_occupation_label': 14,\n",
      " 'user_occupation_text': b'sales/marketing',\n",
      " 'user_rating': 3.0,\n",
      " 'user_zip_code': b'37922'}\n"
     ]
    }
   ],
   "source": [
    "#The ratings dataset returns a dictionary of movie id, user id, the assigned rating, timestamp, movie information, and user information:\n",
    "#View the data from ratings dataset:\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c8372ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': b'[7]', 'movie_id': b'1251', 'movie_title': b'Eight and half '}\n"
     ]
    }
   ],
   "source": [
    "#The ratings dataset returns a dictionary of movie id, user id, the assigned rating, timestamp, movie information, and user information:\n",
    "#View the data from ratings dataset:\n",
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7777c6",
   "metadata": {},
   "source": [
    "As shown beloW, DCN-v2 showing that below features are highly correlated with user_id so the main focus in terms of features will be \"user_occupation_text\", \"user_gender\", \"director\", \"star\", \"bucketized_user_age\":\n",
    "\n",
    "![Personal_dataset_features_importance](https://user-images.githubusercontent.com/67468718/140880610-d32918b7-ba3e-44ac-be20-d274608aae14.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13a3633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "                                \"movie_title\": x[\"movie_title\"],\n",
    "                                \"user_id\": x[\"user_id\"],\n",
    "                                \"user_rating\": x[\"user_rating\"],\n",
    "                                \"timestamp\": x[\"timestamp\"],\n",
    "                                #\"bucketized_user_age\": x['bucketized_user_age'],\n",
    "                                \"gender\": tf.dtypes.cast(x[\"user_gender\"], tf.int64),\n",
    "                                \"director\": x[\"director\"],\n",
    "                                \"star\": x[\"star\"],\n",
    "                               })\n",
    "movies = movies.map(lambda x: {\n",
    "                                \"movie_title\": x[\"movie_title\"], \n",
    "                                \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be37aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use a random split, putting 75% of the ratings in the train set, and 25% in the test set:\n",
    "# Assign a seed=42 for consistency of results and reproducibility:\n",
    "seed = 42\n",
    "l = len(ratings)\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "shuffled = ratings.shuffle(l, seed=seed, reshuffle_each_iteration=False)\n",
    "\n",
    "#Save 75% of the data for training and 25% for testing:\n",
    "train_ = int(0.75 * l)\n",
    "test_ = int(0.25 * l)\n",
    "\n",
    "train = shuffled.take(train_)\n",
    "test = shuffled.skip(train_).take(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d28f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(1_000_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(800_000)\n",
    "test = shuffled.skip(800_000).take(200_000)\n",
    "\n",
    "movie_titles = movies.batch(10_000).map(lambda x: x[\"movie_title\"])\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7669611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b' Pret-a-Porter (Ready to Wear)', b\"'night, Mother\",\n",
       "       b'...And God Created Woman (Et Dieu... crea la femme)',\n",
       "       b'...And Justice for All', b'1-900', b'10 Things I Hate About You',\n",
       "       b'101 Dalmatians', b'12 Angry Men', b'2 Days in the Valley',\n",
       "       b'2 or 3 Things I Know About Her'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "# take a look at the movies:\n",
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de7bd992",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9944b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age = ratings.batch(1_000_000).map(lambda x: x[\"bucketized_user_age\"])\n",
    "unique_user_age = np.unique(np.concatenate(list(user_age)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd657b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_age = unique_user_age.max()\n",
    "min_age = unique_user_age.min()\n",
    "\n",
    "age_buckets = np.linspace(\n",
    "                         min_age, \n",
    "                         max_age, \n",
    "                         num=7,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08941b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c6378e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_gender = ratings.batch(1_000_000).map(lambda x: x['gender'] )\n",
    "unique_user_gender = np.unique(np.concatenate(list(user_gender)))\n",
    "unique_user_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb239ec9",
   "metadata": {},
   "source": [
    "## 4. A Multi-Task Model\n",
    "\n",
    "There are two critical parts to multi-task recommenders:\n",
    "\n",
    "1. They optimize for two or more objectives, and so have two or more losses.\n",
    "2. They share variables between the tasks, allowing for transfer learning.\n",
    "\n",
    "Now, let's define our models as before, but instead of having  a single task, we will have two tasks: one that predicts ratings, and one that predicts movie watches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39e9252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add 1 to account for the unknown token.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 2, embedding_dimension)\n",
    "])\n",
    "\n",
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_movie_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 2, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5bb57",
   "metadata": {},
   "source": [
    "However, now we will have two tasks. The first is the rating task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19087f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.tasks.ranking.Ranking at 0x188502b07c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrs.tasks.Ranking(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba80343",
   "metadata": {},
   "source": [
    "Its goal is to predict the ratings as accurately as possible.\n",
    "\n",
    "The second is the retrieval task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8aa8696d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.tasks.retrieval.Retrieval at 0x18844532608>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=movies.batch(128)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21411b",
   "metadata": {},
   "source": [
    "As before, this task's goal is to predict which movies the user will or will not watch.\n",
    "\n",
    "**Putting it together**\n",
    "\n",
    "We put it all together in a model class.\n",
    "\n",
    "The new component here is that - since we have two tasks and two losses - we need to decide on how important each loss is. We can do this by giving each of the losses a weight, and treating these weights as hyperparameters. If we assign a large loss weight to the rating task, our model is going to focus on predicting ratings (but still use some information from the retrieval task); if we assign a large loss weight to the retrieval task, it will focus on retrieval instead.\n",
    "\n",
    "Below classes were re configured to accomodate the new embedding design due to new features, having deeper neural networks and adding regularization to help overfitting:\n",
    " * class UserModel\n",
    " * class QueryModel\n",
    " * class MovieModel\n",
    " * class MovieModel\n",
    " * class CandidateModel\n",
    " * class MovielensModel\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c522e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension),\n",
    "\n",
    "        ])\n",
    "        self.timestamp_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.Discretization(timestamp_buckets.tolist()),\n",
    "            tf.keras.layers.Embedding(len(timestamp_buckets) + 1, embedding_dimension),\n",
    "\n",
    "        ])\n",
    "        self.normalized_timestamp = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "\n",
    "        self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "      #  self.age_embedding = tf.keras.Sequential([\n",
    "       #     tf.keras.layers.experimental.preprocessing.Discretization(age_buckets.tolist()),\n",
    "        #    tf.keras.layers.Embedding(len(age_buckets) + 1, embedding_dimension//2),\n",
    "      #  ])\n",
    "\n",
    "        #self.normalized_age = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "\n",
    "       # self.normalized_age.adapt(unique_user_age)\n",
    "\n",
    "        self.gender_embedding = tf.keras.layers.experimental.preprocessing.CategoryEncoding(\n",
    "            max_tokens=len(unique_user_gender) + 1)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Take the input dictionary, pass it through each input layer,\n",
    "        # and concatenate the result.\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"user_id\"]),\n",
    "            self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "            self.normalized_timestamp(inputs[\"timestamp\"]),\n",
    "            #self.age_embedding(inputs[\"user_age\"]),\n",
    "            #self.normalized_age(inputs[\"user_age\"]),\n",
    "            self.gender_embedding(inputs[\"gender\"])\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "871e8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding user queries.\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        \"\"\"Model for encoding user queries.\n",
    "\n",
    "        Args:\n",
    "          layer_sizes:\n",
    "            A list of integers where the i-th entry represents the number of units\n",
    "            the i-th layer contains.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # We first use the user model for generating embeddings.\n",
    "        self.embedding_model = UserModel()\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "            self.dense_layers.add(tf.keras.layers.Dropout(0.2))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "564c05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        max_tokens = 10_000\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        self.title_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "              vocabulary=unique_movie_titles,mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension),\n",
    "\n",
    "        ])\n",
    "\n",
    "        self.title_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "            max_tokens=max_tokens)\n",
    "\n",
    "        self.title_text_embedding = tf.keras.Sequential([\n",
    "          self.title_vectorizer,\n",
    "          tf.keras.layers.Embedding(max_tokens, embedding_dimension, mask_zero=True),\n",
    "          tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        ])\n",
    "\n",
    "        self.title_vectorizer.adapt(movies.map(lambda x: x['movie_title']))\n",
    "\n",
    "    def call(self, titles):\n",
    "        return tf.concat([\n",
    "            self.title_embedding(titles),\n",
    "            self.title_text_embedding(titles),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b97c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding movies.\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        \"\"\"Model for encoding movies.\n",
    "\n",
    "        Args:\n",
    "          layer_sizes:\n",
    "            A list of integers where the i-th entry represents the number of units\n",
    "            the i-th layer contains.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_model = MovieModel()\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "            self.dense_layers.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "            feature_embedding = self.embedding_model(inputs)\n",
    "            return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07852974",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MovielensModel(tfrs.models.Model):\n",
    "    def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "        # We take the loss weights in the constructor: this allows us to instantiate\n",
    "        # several model objects with different loss weights.\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        layer_sizes = [64, 32, 32, 32, 32]\n",
    "\n",
    "        # User and movie models.\n",
    "        self.movie_model: tf.keras.layers.Layer = CandidateModel(layer_sizes)\n",
    "\n",
    "        self.user_model: tf.keras.layers.Layer = QueryModel(layer_sizes)\n",
    "\n",
    "        # A small model to take in user and movie embeddings and predict ratings.\n",
    "        # We can make this as complicated as we want as long as we output a scalar\n",
    "        # as our prediction.\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ])\n",
    "\n",
    "        # The tasks.\n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=movies.batch(128).map(lambda x: x['movie_title']).map(self.movie_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model({\n",
    "            \"user_id\": features[\"user_id\"],\n",
    "            \"timestamp\": features[\"timestamp\"],\n",
    "           # \"user_age\": features[\"user_age\"],\n",
    "            \"gender\": features[\"gender\"],\n",
    "        })\n",
    "        # And pick out the movie features and pass them into the movie model.\n",
    "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            # We apply the multi-layered rating model to a concatentation of\n",
    "            # user and movie embeddings.\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "\n",
    "        # We compute the loss for each task.\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=features[\"user_rating\"],\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "        # And combine them using the loss weights.\n",
    "        return (self.rating_weight * rating_loss\n",
    "                + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91870efe",
   "metadata": {},
   "source": [
    "### 4.1  Joint model\n",
    "\n",
    "Let's now train a model that assigns positive weights to both tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9113215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ded133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then shuffle, batch, and cache the training and evaluation data:\n",
    "# Segment the batches so that the model runs 13 training batches (2^13) and 11 test batches (2^11) per epoch, \n",
    "# while having a batch size which is a multiple of 2^n.\n",
    "cached_train = train.shuffle(1_000_000).batch(8192).cache()\n",
    "cached_test = test.batch(2048).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da20162b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "98/98 [==============================] - ETA: 0s - root_mean_squared_error: 1.6874 - factorized_top_k/top_1_categorical_accuracy: 4.5625e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0029 - factorized_top_k/top_10_categorical_accuracy: 0.0054 - factorized_top_k/top_50_categorical_accuracy: 0.0230 - factorized_top_k/top_100_categorical_accuracy: 0.0424 - loss: 73486.9777 - regularization_loss: 0.0000e+00 - total_loss: 73486.9777WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "98/98 [==============================] - 205s 2s/step - root_mean_squared_error: 1.6874 - factorized_top_k/top_1_categorical_accuracy: 4.5625e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0029 - factorized_top_k/top_10_categorical_accuracy: 0.0054 - factorized_top_k/top_50_categorical_accuracy: 0.0230 - factorized_top_k/top_100_categorical_accuracy: 0.0424 - loss: 73205.7619 - regularization_loss: 0.0000e+00 - total_loss: 73205.7619 - val_root_mean_squared_error: 1.0994 - val_factorized_top_k/top_1_categorical_accuracy: 3.2500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0018 - val_factorized_top_k/top_10_categorical_accuracy: 0.0036 - val_factorized_top_k/top_50_categorical_accuracy: 0.0204 - val_factorized_top_k/top_100_categorical_accuracy: 0.0382 - val_loss: 9562.5479 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9562.5479\n",
      "Epoch 2/32\n",
      "98/98 [==============================] - 185s 2s/step - root_mean_squared_error: 1.0896 - factorized_top_k/top_1_categorical_accuracy: 2.0875e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0015 - factorized_top_k/top_10_categorical_accuracy: 0.0030 - factorized_top_k/top_50_categorical_accuracy: 0.0146 - factorized_top_k/top_100_categorical_accuracy: 0.0303 - loss: 72372.7931 - regularization_loss: 0.0000e+00 - total_loss: 72372.7931 - val_root_mean_squared_error: 1.0857 - val_factorized_top_k/top_1_categorical_accuracy: 1.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0014 - val_factorized_top_k/top_10_categorical_accuracy: 0.0027 - val_factorized_top_k/top_50_categorical_accuracy: 0.0148 - val_factorized_top_k/top_100_categorical_accuracy: 0.0305 - val_loss: 9506.1113 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9506.1113\n",
      "Epoch 3/32\n",
      "98/98 [==============================] - 222s 2s/step - root_mean_squared_error: 1.0721 - factorized_top_k/top_1_categorical_accuracy: 2.2375e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0014 - factorized_top_k/top_10_categorical_accuracy: 0.0028 - factorized_top_k/top_50_categorical_accuracy: 0.0140 - factorized_top_k/top_100_categorical_accuracy: 0.0290 - loss: 72141.8693 - regularization_loss: 0.0000e+00 - total_loss: 72141.8693 - val_root_mean_squared_error: 1.0822 - val_factorized_top_k/top_1_categorical_accuracy: 2.7000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0018 - val_factorized_top_k/top_10_categorical_accuracy: 0.0033 - val_factorized_top_k/top_50_categorical_accuracy: 0.0171 - val_factorized_top_k/top_100_categorical_accuracy: 0.0333 - val_loss: 9475.0967 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9475.0967\n",
      "Epoch 4/32\n",
      "98/98 [==============================] - 248s 3s/step - root_mean_squared_error: 1.0540 - factorized_top_k/top_1_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0015 - factorized_top_k/top_10_categorical_accuracy: 0.0030 - factorized_top_k/top_50_categorical_accuracy: 0.0175 - factorized_top_k/top_100_categorical_accuracy: 0.0378 - loss: 71821.5732 - regularization_loss: 0.0000e+00 - total_loss: 71821.5732 - val_root_mean_squared_error: 1.0333 - val_factorized_top_k/top_1_categorical_accuracy: 2.4500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0018 - val_factorized_top_k/top_10_categorical_accuracy: 0.0035 - val_factorized_top_k/top_50_categorical_accuracy: 0.0220 - val_factorized_top_k/top_100_categorical_accuracy: 0.0464 - val_loss: 9366.8105 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9366.8105\n",
      "Epoch 5/32\n",
      "98/98 [==============================] - 249s 3s/step - root_mean_squared_error: 1.0358 - factorized_top_k/top_1_categorical_accuracy: 3.0625e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0021 - factorized_top_k/top_10_categorical_accuracy: 0.0044 - factorized_top_k/top_50_categorical_accuracy: 0.0243 - factorized_top_k/top_100_categorical_accuracy: 0.0515 - loss: 71324.5865 - regularization_loss: 0.0000e+00 - total_loss: 71324.5865 - val_root_mean_squared_error: 1.0276 - val_factorized_top_k/top_1_categorical_accuracy: 2.7000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0022 - val_factorized_top_k/top_10_categorical_accuracy: 0.0050 - val_factorized_top_k/top_50_categorical_accuracy: 0.0281 - val_factorized_top_k/top_100_categorical_accuracy: 0.0569 - val_loss: 9301.4160 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9301.4160\n",
      "Epoch 6/32\n",
      "98/98 [==============================] - 234s 2s/step - root_mean_squared_error: 1.0264 - factorized_top_k/top_1_categorical_accuracy: 4.4500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0031 - factorized_top_k/top_10_categorical_accuracy: 0.0064 - factorized_top_k/top_50_categorical_accuracy: 0.0327 - factorized_top_k/top_100_categorical_accuracy: 0.0656 - loss: 71027.8084 - regularization_loss: 0.0000e+00 - total_loss: 71027.8084 - val_root_mean_squared_error: 1.0239 - val_factorized_top_k/top_1_categorical_accuracy: 5.8500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0044 - val_factorized_top_k/top_10_categorical_accuracy: 0.0089 - val_factorized_top_k/top_50_categorical_accuracy: 0.0427 - val_factorized_top_k/top_100_categorical_accuracy: 0.0799 - val_loss: 9288.1846 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9288.1846\n",
      "Epoch 7/32\n",
      "98/98 [==============================] - 235s 2s/step - root_mean_squared_error: 1.0207 - factorized_top_k/top_1_categorical_accuracy: 6.7250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0042 - factorized_top_k/top_10_categorical_accuracy: 0.0087 - factorized_top_k/top_50_categorical_accuracy: 0.0416 - factorized_top_k/top_100_categorical_accuracy: 0.0809 - loss: 70800.9969 - regularization_loss: 0.0000e+00 - total_loss: 70800.9969 - val_root_mean_squared_error: 1.0146 - val_factorized_top_k/top_1_categorical_accuracy: 6.4500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0050 - val_factorized_top_k/top_10_categorical_accuracy: 0.0104 - val_factorized_top_k/top_50_categorical_accuracy: 0.0491 - val_factorized_top_k/top_100_categorical_accuracy: 0.0910 - val_loss: 9251.0508 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9251.0508\n",
      "Epoch 8/32\n",
      "98/98 [==============================] - 232s 2s/step - root_mean_squared_error: 1.0133 - factorized_top_k/top_1_categorical_accuracy: 8.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0051 - factorized_top_k/top_10_categorical_accuracy: 0.0103 - factorized_top_k/top_50_categorical_accuracy: 0.0484 - factorized_top_k/top_100_categorical_accuracy: 0.0913 - loss: 70580.1746 - regularization_loss: 0.0000e+00 - total_loss: 70580.1746 - val_root_mean_squared_error: 1.0105 - val_factorized_top_k/top_1_categorical_accuracy: 6.1000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0049 - val_factorized_top_k/top_10_categorical_accuracy: 0.0102 - val_factorized_top_k/top_50_categorical_accuracy: 0.0499 - val_factorized_top_k/top_100_categorical_accuracy: 0.0934 - val_loss: 9224.2461 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9224.2461\n",
      "Epoch 9/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 232s 2s/step - root_mean_squared_error: 1.0107 - factorized_top_k/top_1_categorical_accuracy: 7.5500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0048 - factorized_top_k/top_10_categorical_accuracy: 0.0100 - factorized_top_k/top_50_categorical_accuracy: 0.0493 - factorized_top_k/top_100_categorical_accuracy: 0.0949 - loss: 70380.0711 - regularization_loss: 0.0000e+00 - total_loss: 70380.0711 - val_root_mean_squared_error: 1.0104 - val_factorized_top_k/top_1_categorical_accuracy: 6.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0049 - val_factorized_top_k/top_10_categorical_accuracy: 0.0099 - val_factorized_top_k/top_50_categorical_accuracy: 0.0501 - val_factorized_top_k/top_100_categorical_accuracy: 0.0974 - val_loss: 9207.5371 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9207.5371\n",
      "Epoch 10/32\n",
      "98/98 [==============================] - 231s 2s/step - root_mean_squared_error: 1.0081 - factorized_top_k/top_1_categorical_accuracy: 6.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0046 - factorized_top_k/top_10_categorical_accuracy: 0.0096 - factorized_top_k/top_50_categorical_accuracy: 0.0501 - factorized_top_k/top_100_categorical_accuracy: 0.0979 - loss: 70226.0765 - regularization_loss: 0.0000e+00 - total_loss: 70226.0765 - val_root_mean_squared_error: 1.0115 - val_factorized_top_k/top_1_categorical_accuracy: 5.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0048 - val_factorized_top_k/top_10_categorical_accuracy: 0.0104 - val_factorized_top_k/top_50_categorical_accuracy: 0.0542 - val_factorized_top_k/top_100_categorical_accuracy: 0.1046 - val_loss: 9191.0732 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9191.0732\n",
      "Epoch 11/32\n",
      "98/98 [==============================] - 233s 2s/step - root_mean_squared_error: 1.0069 - factorized_top_k/top_1_categorical_accuracy: 6.3375e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0045 - factorized_top_k/top_10_categorical_accuracy: 0.0099 - factorized_top_k/top_50_categorical_accuracy: 0.0528 - factorized_top_k/top_100_categorical_accuracy: 0.1036 - loss: 70092.9823 - regularization_loss: 0.0000e+00 - total_loss: 70092.9823 - val_root_mean_squared_error: 1.0114 - val_factorized_top_k/top_1_categorical_accuracy: 4.7500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0046 - val_factorized_top_k/top_10_categorical_accuracy: 0.0101 - val_factorized_top_k/top_50_categorical_accuracy: 0.0552 - val_factorized_top_k/top_100_categorical_accuracy: 0.1063 - val_loss: 9188.6533 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9188.6533\n",
      "Epoch 12/32\n",
      "98/98 [==============================] - 244s 2s/step - root_mean_squared_error: 1.0066 - factorized_top_k/top_1_categorical_accuracy: 5.9125e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0045 - factorized_top_k/top_10_categorical_accuracy: 0.0101 - factorized_top_k/top_50_categorical_accuracy: 0.0548 - factorized_top_k/top_100_categorical_accuracy: 0.1068 - loss: 69999.3662 - regularization_loss: 0.0000e+00 - total_loss: 69999.3662 - val_root_mean_squared_error: 1.0045 - val_factorized_top_k/top_1_categorical_accuracy: 4.6000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0043 - val_factorized_top_k/top_10_categorical_accuracy: 0.0096 - val_factorized_top_k/top_50_categorical_accuracy: 0.0534 - val_factorized_top_k/top_100_categorical_accuracy: 0.1051 - val_loss: 9172.5498 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9172.5498\n",
      "Epoch 13/32\n",
      "98/98 [==============================] - 251s 3s/step - root_mean_squared_error: 1.0040 - factorized_top_k/top_1_categorical_accuracy: 5.7125e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0049 - factorized_top_k/top_10_categorical_accuracy: 0.0108 - factorized_top_k/top_50_categorical_accuracy: 0.0585 - factorized_top_k/top_100_categorical_accuracy: 0.1129 - loss: 69885.6085 - regularization_loss: 0.0000e+00 - total_loss: 69885.6085 - val_root_mean_squared_error: 1.0172 - val_factorized_top_k/top_1_categorical_accuracy: 3.9500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0046 - val_factorized_top_k/top_10_categorical_accuracy: 0.0109 - val_factorized_top_k/top_50_categorical_accuracy: 0.0588 - val_factorized_top_k/top_100_categorical_accuracy: 0.1145 - val_loss: 9152.8018 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9152.8018\n",
      "Epoch 14/32\n",
      "98/98 [==============================] - 245s 3s/step - root_mean_squared_error: 1.0026 - factorized_top_k/top_1_categorical_accuracy: 5.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0049 - factorized_top_k/top_10_categorical_accuracy: 0.0110 - factorized_top_k/top_50_categorical_accuracy: 0.0606 - factorized_top_k/top_100_categorical_accuracy: 0.1164 - loss: 69797.4508 - regularization_loss: 0.0000e+00 - total_loss: 69797.4508 - val_root_mean_squared_error: 1.0022 - val_factorized_top_k/top_1_categorical_accuracy: 4.9000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0047 - val_factorized_top_k/top_10_categorical_accuracy: 0.0107 - val_factorized_top_k/top_50_categorical_accuracy: 0.0590 - val_factorized_top_k/top_100_categorical_accuracy: 0.1148 - val_loss: 9136.2441 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9136.2441\n",
      "Epoch 15/32\n",
      "98/98 [==============================] - 244s 2s/step - root_mean_squared_error: 1.0018 - factorized_top_k/top_1_categorical_accuracy: 5.9625e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0052 - factorized_top_k/top_10_categorical_accuracy: 0.0117 - factorized_top_k/top_50_categorical_accuracy: 0.0628 - factorized_top_k/top_100_categorical_accuracy: 0.1199 - loss: 69713.4908 - regularization_loss: 0.0000e+00 - total_loss: 69713.4908 - val_root_mean_squared_error: 1.0049 - val_factorized_top_k/top_1_categorical_accuracy: 4.6500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0050 - val_factorized_top_k/top_10_categorical_accuracy: 0.0114 - val_factorized_top_k/top_50_categorical_accuracy: 0.0618 - val_factorized_top_k/top_100_categorical_accuracy: 0.1186 - val_loss: 9128.7910 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9128.7910\n",
      "Epoch 16/32\n",
      "98/98 [==============================] - 240s 2s/step - root_mean_squared_error: 0.9993 - factorized_top_k/top_1_categorical_accuracy: 5.3000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0051 - factorized_top_k/top_10_categorical_accuracy: 0.0116 - factorized_top_k/top_50_categorical_accuracy: 0.0633 - factorized_top_k/top_100_categorical_accuracy: 0.1216 - loss: 69639.2618 - regularization_loss: 0.0000e+00 - total_loss: 69639.2618 - val_root_mean_squared_error: 1.0065 - val_factorized_top_k/top_1_categorical_accuracy: 4.9000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0047 - val_factorized_top_k/top_10_categorical_accuracy: 0.0106 - val_factorized_top_k/top_50_categorical_accuracy: 0.0593 - val_factorized_top_k/top_100_categorical_accuracy: 0.1151 - val_loss: 9126.0312 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9126.0312\n",
      "Epoch 17/32\n",
      "98/98 [==============================] - 249s 3s/step - root_mean_squared_error: 0.9996 - factorized_top_k/top_1_categorical_accuracy: 5.8375e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0053 - factorized_top_k/top_10_categorical_accuracy: 0.0121 - factorized_top_k/top_50_categorical_accuracy: 0.0654 - factorized_top_k/top_100_categorical_accuracy: 0.1241 - loss: 69577.0631 - regularization_loss: 0.0000e+00 - total_loss: 69577.0631 - val_root_mean_squared_error: 1.0004 - val_factorized_top_k/top_1_categorical_accuracy: 4.3500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0048 - val_factorized_top_k/top_10_categorical_accuracy: 0.0112 - val_factorized_top_k/top_50_categorical_accuracy: 0.0635 - val_factorized_top_k/top_100_categorical_accuracy: 0.1213 - val_loss: 9118.7441 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9118.7441\n",
      "Epoch 18/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 253s 3s/step - root_mean_squared_error: 0.9966 - factorized_top_k/top_1_categorical_accuracy: 5.4125e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0053 - factorized_top_k/top_10_categorical_accuracy: 0.0121 - factorized_top_k/top_50_categorical_accuracy: 0.0662 - factorized_top_k/top_100_categorical_accuracy: 0.1264 - loss: 69514.2461 - regularization_loss: 0.0000e+00 - total_loss: 69514.2461 - val_root_mean_squared_error: 1.0061 - val_factorized_top_k/top_1_categorical_accuracy: 4.7000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0046 - val_factorized_top_k/top_10_categorical_accuracy: 0.0108 - val_factorized_top_k/top_50_categorical_accuracy: 0.0624 - val_factorized_top_k/top_100_categorical_accuracy: 0.1200 - val_loss: 9111.0703 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9111.0703\n",
      "Epoch 19/32\n",
      "98/98 [==============================] - 244s 2s/step - root_mean_squared_error: 0.9976 - factorized_top_k/top_1_categorical_accuracy: 5.4125e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0051 - factorized_top_k/top_10_categorical_accuracy: 0.0120 - factorized_top_k/top_50_categorical_accuracy: 0.0668 - factorized_top_k/top_100_categorical_accuracy: 0.1277 - loss: 69464.6503 - regularization_loss: 0.0000e+00 - total_loss: 69464.6503 - val_root_mean_squared_error: 0.9983 - val_factorized_top_k/top_1_categorical_accuracy: 3.9500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0047 - val_factorized_top_k/top_10_categorical_accuracy: 0.0110 - val_factorized_top_k/top_50_categorical_accuracy: 0.0643 - val_factorized_top_k/top_100_categorical_accuracy: 0.1244 - val_loss: 9108.8008 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9108.8008\n",
      "Epoch 20/32\n",
      "98/98 [==============================] - 262s 3s/step - root_mean_squared_error: 0.9957 - factorized_top_k/top_1_categorical_accuracy: 5.2375e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0051 - factorized_top_k/top_10_categorical_accuracy: 0.0120 - factorized_top_k/top_50_categorical_accuracy: 0.0677 - factorized_top_k/top_100_categorical_accuracy: 0.1291 - loss: 69413.5867 - regularization_loss: 0.0000e+00 - total_loss: 69413.5867 - val_root_mean_squared_error: 1.0021 - val_factorized_top_k/top_1_categorical_accuracy: 3.7500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0045 - val_factorized_top_k/top_10_categorical_accuracy: 0.0108 - val_factorized_top_k/top_50_categorical_accuracy: 0.0638 - val_factorized_top_k/top_100_categorical_accuracy: 0.1228 - val_loss: 9105.8076 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9105.8076\n",
      "Epoch 21/32\n",
      "98/98 [==============================] - 272s 3s/step - root_mean_squared_error: 0.9951 - factorized_top_k/top_1_categorical_accuracy: 5.0375e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0051 - factorized_top_k/top_10_categorical_accuracy: 0.0121 - factorized_top_k/top_50_categorical_accuracy: 0.0686 - factorized_top_k/top_100_categorical_accuracy: 0.1303 - loss: 69372.8226 - regularization_loss: 0.0000e+00 - total_loss: 69372.8226 - val_root_mean_squared_error: 0.9991 - val_factorized_top_k/top_1_categorical_accuracy: 3.7500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0042 - val_factorized_top_k/top_10_categorical_accuracy: 0.0103 - val_factorized_top_k/top_50_categorical_accuracy: 0.0629 - val_factorized_top_k/top_100_categorical_accuracy: 0.1212 - val_loss: 9100.7656 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9100.7656\n",
      "Epoch 22/32\n",
      "98/98 [==============================] - 271s 3s/step - root_mean_squared_error: 0.9952 - factorized_top_k/top_1_categorical_accuracy: 4.9000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0049 - factorized_top_k/top_10_categorical_accuracy: 0.0119 - factorized_top_k/top_50_categorical_accuracy: 0.0691 - factorized_top_k/top_100_categorical_accuracy: 0.1312 - loss: 69337.5657 - regularization_loss: 0.0000e+00 - total_loss: 69337.5657 - val_root_mean_squared_error: 0.9972 - val_factorized_top_k/top_1_categorical_accuracy: 3.4500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0043 - val_factorized_top_k/top_10_categorical_accuracy: 0.0107 - val_factorized_top_k/top_50_categorical_accuracy: 0.0645 - val_factorized_top_k/top_100_categorical_accuracy: 0.1248 - val_loss: 9097.6797 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9097.6797\n",
      "Epoch 23/32\n",
      "98/98 [==============================] - 268s 3s/step - root_mean_squared_error: 0.9938 - factorized_top_k/top_1_categorical_accuracy: 4.3375e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0050 - factorized_top_k/top_10_categorical_accuracy: 0.0122 - factorized_top_k/top_50_categorical_accuracy: 0.0695 - factorized_top_k/top_100_categorical_accuracy: 0.1324 - loss: 69303.7705 - regularization_loss: 0.0000e+00 - total_loss: 69303.7705 - val_root_mean_squared_error: 0.9978 - val_factorized_top_k/top_1_categorical_accuracy: 3.5500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0043 - val_factorized_top_k/top_10_categorical_accuracy: 0.0108 - val_factorized_top_k/top_50_categorical_accuracy: 0.0655 - val_factorized_top_k/top_100_categorical_accuracy: 0.1260 - val_loss: 9095.3955 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9095.3955\n",
      "Epoch 24/32\n",
      "98/98 [==============================] - 276s 3s/step - root_mean_squared_error: 0.9940 - factorized_top_k/top_1_categorical_accuracy: 4.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0051 - factorized_top_k/top_10_categorical_accuracy: 0.0122 - factorized_top_k/top_50_categorical_accuracy: 0.0705 - factorized_top_k/top_100_categorical_accuracy: 0.1342 - loss: 69271.2198 - regularization_loss: 0.0000e+00 - total_loss: 69271.2198 - val_root_mean_squared_error: 0.9961 - val_factorized_top_k/top_1_categorical_accuracy: 3.4500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0041 - val_factorized_top_k/top_10_categorical_accuracy: 0.0109 - val_factorized_top_k/top_50_categorical_accuracy: 0.0663 - val_factorized_top_k/top_100_categorical_accuracy: 0.1269 - val_loss: 9093.9238 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9093.9238\n",
      "Epoch 25/32\n",
      "98/98 [==============================] - 276s 3s/step - root_mean_squared_error: 0.9921 - factorized_top_k/top_1_categorical_accuracy: 4.1625e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0049 - factorized_top_k/top_10_categorical_accuracy: 0.0121 - factorized_top_k/top_50_categorical_accuracy: 0.0708 - factorized_top_k/top_100_categorical_accuracy: 0.1349 - loss: 69240.9506 - regularization_loss: 0.0000e+00 - total_loss: 69240.9506 - val_root_mean_squared_error: 1.0019 - val_factorized_top_k/top_1_categorical_accuracy: 2.5500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0042 - val_factorized_top_k/top_10_categorical_accuracy: 0.0109 - val_factorized_top_k/top_50_categorical_accuracy: 0.0656 - val_factorized_top_k/top_100_categorical_accuracy: 0.1259 - val_loss: 9098.7422 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9098.7422\n",
      "Epoch 26/32\n",
      "98/98 [==============================] - 275s 3s/step - root_mean_squared_error: 0.9934 - factorized_top_k/top_1_categorical_accuracy: 3.8375e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0048 - factorized_top_k/top_10_categorical_accuracy: 0.0122 - factorized_top_k/top_50_categorical_accuracy: 0.0713 - factorized_top_k/top_100_categorical_accuracy: 0.1353 - loss: 69216.0285 - regularization_loss: 0.0000e+00 - total_loss: 69216.0285 - val_root_mean_squared_error: 0.9948 - val_factorized_top_k/top_1_categorical_accuracy: 2.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0041 - val_factorized_top_k/top_10_categorical_accuracy: 0.0109 - val_factorized_top_k/top_50_categorical_accuracy: 0.0660 - val_factorized_top_k/top_100_categorical_accuracy: 0.1271 - val_loss: 9093.4775 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9093.4775\n",
      "Epoch 27/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 264s 3s/step - root_mean_squared_error: 0.9918 - factorized_top_k/top_1_categorical_accuracy: 3.5750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0048 - factorized_top_k/top_10_categorical_accuracy: 0.0122 - factorized_top_k/top_50_categorical_accuracy: 0.0720 - factorized_top_k/top_100_categorical_accuracy: 0.1363 - loss: 69191.0257 - regularization_loss: 0.0000e+00 - total_loss: 69191.0257 - val_root_mean_squared_error: 0.9946 - val_factorized_top_k/top_1_categorical_accuracy: 2.7500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0040 - val_factorized_top_k/top_10_categorical_accuracy: 0.0108 - val_factorized_top_k/top_50_categorical_accuracy: 0.0668 - val_factorized_top_k/top_100_categorical_accuracy: 0.1272 - val_loss: 9095.4834 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9095.4834\n",
      "Epoch 28/32\n",
      "98/98 [==============================] - 273s 3s/step - root_mean_squared_error: 0.9914 - factorized_top_k/top_1_categorical_accuracy: 3.5625e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0047 - factorized_top_k/top_10_categorical_accuracy: 0.0121 - factorized_top_k/top_50_categorical_accuracy: 0.0722 - factorized_top_k/top_100_categorical_accuracy: 0.1370 - loss: 69170.0687 - regularization_loss: 0.0000e+00 - total_loss: 69170.0687 - val_root_mean_squared_error: 0.9993 - val_factorized_top_k/top_1_categorical_accuracy: 2.8500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0039 - val_factorized_top_k/top_10_categorical_accuracy: 0.0107 - val_factorized_top_k/top_50_categorical_accuracy: 0.0656 - val_factorized_top_k/top_100_categorical_accuracy: 0.1261 - val_loss: 9090.5996 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9090.5996\n",
      "Epoch 29/32\n",
      "98/98 [==============================] - 276s 3s/step - root_mean_squared_error: 0.9919 - factorized_top_k/top_1_categorical_accuracy: 3.8875e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0047 - factorized_top_k/top_10_categorical_accuracy: 0.0122 - factorized_top_k/top_50_categorical_accuracy: 0.0728 - factorized_top_k/top_100_categorical_accuracy: 0.1376 - loss: 69148.5316 - regularization_loss: 0.0000e+00 - total_loss: 69148.5316 - val_root_mean_squared_error: 0.9927 - val_factorized_top_k/top_1_categorical_accuracy: 2.8000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0042 - val_factorized_top_k/top_10_categorical_accuracy: 0.0108 - val_factorized_top_k/top_50_categorical_accuracy: 0.0664 - val_factorized_top_k/top_100_categorical_accuracy: 0.1277 - val_loss: 9086.2285 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9086.2285\n",
      "Epoch 30/32\n",
      "98/98 [==============================] - 269s 3s/step - root_mean_squared_error: 0.9904 - factorized_top_k/top_1_categorical_accuracy: 3.7750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0047 - factorized_top_k/top_10_categorical_accuracy: 0.0121 - factorized_top_k/top_50_categorical_accuracy: 0.0727 - factorized_top_k/top_100_categorical_accuracy: 0.1381 - loss: 69128.5414 - regularization_loss: 0.0000e+00 - total_loss: 69128.5414 - val_root_mean_squared_error: 0.9964 - val_factorized_top_k/top_1_categorical_accuracy: 2.4500e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0040 - val_factorized_top_k/top_10_categorical_accuracy: 0.0107 - val_factorized_top_k/top_50_categorical_accuracy: 0.0660 - val_factorized_top_k/top_100_categorical_accuracy: 0.1267 - val_loss: 9086.8809 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9086.8809\n",
      "Epoch 31/32\n",
      "98/98 [==============================] - 277s 3s/step - root_mean_squared_error: 0.9907 - factorized_top_k/top_1_categorical_accuracy: 3.2375e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0047 - factorized_top_k/top_10_categorical_accuracy: 0.0123 - factorized_top_k/top_50_categorical_accuracy: 0.0731 - factorized_top_k/top_100_categorical_accuracy: 0.1383 - loss: 69115.9190 - regularization_loss: 0.0000e+00 - total_loss: 69115.9190 - val_root_mean_squared_error: 0.9944 - val_factorized_top_k/top_1_categorical_accuracy: 2.7000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0039 - val_factorized_top_k/top_10_categorical_accuracy: 0.0107 - val_factorized_top_k/top_50_categorical_accuracy: 0.0657 - val_factorized_top_k/top_100_categorical_accuracy: 0.1269 - val_loss: 9089.3105 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9089.3105\n",
      "Epoch 32/32\n",
      "98/98 [==============================] - 274s 3s/step - root_mean_squared_error: 0.9906 - factorized_top_k/top_1_categorical_accuracy: 3.5375e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0048 - factorized_top_k/top_10_categorical_accuracy: 0.0123 - factorized_top_k/top_50_categorical_accuracy: 0.0732 - factorized_top_k/top_100_categorical_accuracy: 0.1386 - loss: 69097.5050 - regularization_loss: 0.0000e+00 - total_loss: 69097.5050 - val_root_mean_squared_error: 0.9917 - val_factorized_top_k/top_1_categorical_accuracy: 2.9000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0042 - val_factorized_top_k/top_10_categorical_accuracy: 0.0110 - val_factorized_top_k/top_50_categorical_accuracy: 0.0670 - val_factorized_top_k/top_100_categorical_accuracy: 0.1288 - val_loss: 9092.6357 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9092.6357\n"
     ]
    }
   ],
   "source": [
    "Final = model.fit(cached_train, validation_data = cached_test, epochs=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c748c2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 37s 377ms/step - root_mean_squared_error: 0.9917 - factorized_top_k/top_1_categorical_accuracy: 2.9000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0042 - factorized_top_k/top_10_categorical_accuracy: 0.0110 - factorized_top_k/top_50_categorical_accuracy: 0.0670 - factorized_top_k/top_100_categorical_accuracy: 0.1288 - loss: 14609.1232 - regularization_loss: 0.0000e+00 - total_loss: 14609.1232\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74cceddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 0.9916684031486511,\n",
       " 'factorized_top_k/top_1_categorical_accuracy': 0.0002899999963119626,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.004155000206083059,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.01104000024497509,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.0669500008225441,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.1288049966096878,\n",
       " 'loss': 9092.6357421875,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 9092.6357421875}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec21436",
   "metadata": {},
   "source": [
    "Better, over all results compared to the previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc34da",
   "metadata": {},
   "source": [
    "## 5. Modeling Summary\n",
    "\n",
    "Alright, as shown below joint model managed to provide both better prediction with low RMSE, as shown below:\n",
    "\n",
    " |Models|Retrieval top-100 accuracy | Ranking RMSE|\n",
    " |:--:|:--:|:--:|\n",
    "  |Model 1: Rating-specialized model|0.031|0.940|\n",
    " |Model 2: Retrieval-specialized model|0.158|3.868|\n",
    " |Model 3: Joint model|0.158|0.974|\n",
    " |Model 4: Joint model (Tuned)|0.129|0.992|\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e10284b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c216e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfrs] *",
   "language": "python",
   "name": "conda-env-tfrs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
