{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab2989f",
   "metadata": {},
   "source": [
    "# MAXELLA TFRS: Multi-Task Model - Joint Model\n",
    "\n",
    "## The Two-Tower and Ranking Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859153c",
   "metadata": {},
   "source": [
    "## Contents \n",
    "\n",
    "\n",
    " * Introduction\n",
    " * Dataset\n",
    " * Sourcing and Loading\n",
    " * A Multi-Task Model\n",
    "   * Rating-specialized Model\n",
    "   * Retrieval-specialized Model\n",
    "   * Joint Model\n",
    " * Modeling Summary\n",
    " * Next Step - Joint Model Tuning\n",
    "   * Adding more features\n",
    "   * Optimize Embedding\n",
    "   * embedding_dimension 32 to 64\n",
    "   * epochs= 3 to 32\n",
    "   * Learning rate\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc786173",
   "metadata": {},
   "source": [
    "## 1. Introduction \n",
    "\n",
    "In the [TFRS Modeling - Two-Tower](https://github.com/akthammomani/MAXELLA-APP-Movies-Tensorflow-Recommenders-TFRS/tree/main/Notebooks/TFRS-Modelling) we built a retrieval system using movie watches as positive interaction signals.\n",
    "\n",
    "In many applications, however, there are multiple rich sources of feedback to draw upon. For example, an e-commerce site may record user visits to product pages (abundant, but relatively low signal), image clicks, adding to cart, and, finally, purchases. It may even record post-purchase signals such as reviews and returns.\n",
    "\n",
    "Integrating all these different forms of feedback is critical to building systems that users love to use, and that do not optimize for any one metric at the expense of overall performance.\n",
    "\n",
    "In addition, building a joint model for multiple tasks may produce better results than building a number of task-specific models. This is especially true where some data is abundant (for example, clicks), and some data is sparse (purchases, returns, manual reviews). In those scenarios, a joint model may be able to use representations learned from the abundant task to improve its predictions on the sparse task via a phenomenon known as [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning). For example, [this paper](https://openreview.net/pdf?id=SJxPVcSonN) shows that a model predicting explicit user ratings from sparse user surveys can be substantially improved by adding an auxiliary task that uses abundant click log data.\n",
    "\n",
    "In this Notebook, we are going to build a multi-objective recommender for Movielens, using both implicit (movie watches) and explicit signals (ratings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e78703",
   "metadata": {},
   "source": [
    "## 2. Dataset: \n",
    "\n",
    "**Movie Lens** contains a set of movie ratings from the MovieLens website, a movie recommendation service. This dataset was collected and maintained by [GroupLens](https://grouplens.org/) , a research group at the University of Minnesota. There are 5 versions included: \"25m\", \"latest-small\", \"100k\", \"1m\", \"20m\". In all datasets, the movies data and ratings data are joined on \"movieId\". The 25m dataset, latest-small dataset, and 20m dataset contain only movie data and rating data. The 1m dataset and 100k dataset contain demographic data in addition to movie and rating data.\n",
    "\n",
    "**movie_lens/1m** can be treated in two ways:\n",
    "\n",
    "  * It can be interpreted as expressesing which movies the users watched (and rated), and which they did not. This is a form of *implicit feedback*, where users' watches tell us which things they prefer to see and which they'd rather not see (This means that every movie a user watched is a positive example, and every movie they have not seen is an implicit negative example).\n",
    "  * It can also be seen as expressesing how much the users liked the movies they did watch. This is a form of *explicit feedback*: given that a user watched a movie, we can tell roughly how much they liked by looking at the rating they have given.\n",
    "\n",
    "\n",
    "\n",
    "**(a) [movie_lens/1m-ratings](https://www.tensorflow.org/datasets/catalog/movie_lens#movie_lens1m-ratings):**\n",
    " * Config description: This dataset contains 1,000,085 anonymous ratings of approximately 3,619 movies made by 6,040 MovieLens users who joined MovieLens. Ratings are in whole-star increments. This dataset contains demographic data of users in addition to data on movies and ratings.\n",
    " * This dataset is the largest dataset that includes demographic data from movie_lens.\n",
    " * \"user_gender\": gender of the user who made the rating; a true value corresponds to male\n",
    " * \"bucketized_user_age\": bucketized age values of the user who made the rating, the values and the corresponding ranges are:\n",
    "   * 1: \"Under 18\"\n",
    "   * 18: \"18-24\"\n",
    "   * 25: \"25-34\"\n",
    "   * 35: \"35-44\"\n",
    "   * 45: \"45-49\"\n",
    "   * 50: \"50-55\"\n",
    "   * 56: \"56+\"\n",
    " * \"user_occupation_label\": the occupation of the user who made the rating represented by an integer-encoded label; labels are preprocessed to be consistent across different versions\n",
    " * \"user_occupation_text\": the occupation of the user who made the rating in the original string; different versions can have different set of raw text labels\n",
    " * \"user_zip_code\": the zip code of the user who made the rating.\n",
    " * \"release_date\": This is the movie release date, in unix epoch (UTC - units of seconds) (int64).\n",
    " * \"director\": This is the director of the movie.\n",
    " * \"start\": This is the main star of the movie.\n",
    " \n",
    " **(b) [movie_lens/1m-movies](https://www.tensorflow.org/datasets/catalog/movie_lens#movie_lens1m-movies):**\n",
    "\n",
    " * Config description: This dataset contains data of approximately 3,619 movies rated in the 1m dataset.\n",
    " * Download size: 5.64 MiB\n",
    " * Dataset size: 351.12 KiB\n",
    " * Auto-cached ([documentation](https://www.tensorflow.org/datasets/performances#auto-caching)): Yes\n",
    " * Features:\n",
    "```\n",
    "FeaturesDict({\n",
    "              'movie_genres': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=21)),\n",
    "              'movie_id': tf.string,\n",
    "              'movie_title': tf.string,\n",
    "             })\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c9aa4",
   "metadata": {},
   "source": [
    "## 3. Sourcing and Loading\n",
    "\n",
    "### 3.1 Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce3e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary Libararies: \n",
    "\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from typing import Dict, Text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50156f6d",
   "metadata": {},
   "source": [
    "### 3.2 Preparing the dataset\n",
    "\n",
    "Let's first have a look at the data.\n",
    "\n",
    "We use the MovieLens dataset from Tensorflow Datasets. Loading **[movie_lens/1m-ratings](https://www.tensorflow.org/datasets/catalog/movie_lens#movie_lens1m-ratings)** yields a ***tf.data.Dataset*** object containing the ratings data and loading **[movie_lens/1m-movies](https://www.tensorflow.org/datasets/catalog/movie_lens#movie_lens1m-movies)** yields a ***tf.data.Dataset*** object containing only the movies data.\n",
    "\n",
    "Note that since the MovieLens dataset does not have predefined splits, all data are under train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c08762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's look at the final dataframe where we merged tensorflow dataset with movies_metadata.csv and credits.csv**\n",
    "# let's make sure to use encoding argument to avoid in encoding errors !!!\n",
    "ratings = pd.read_csv('ratings.csv', encoding='ISO-8859-1')\n",
    "movies = pd.read_csv('movies.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f47358d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_occupation_label</th>\n",
       "      <th>user_occupation_text</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_zip_code</th>\n",
       "      <th>director</th>\n",
       "      <th>release_date</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>[7]</td>\n",
       "      <td>1251</td>\n",
       "      <td>Eight and half</td>\n",
       "      <td>974089380</td>\n",
       "      <td>False</td>\n",
       "      <td>2497</td>\n",
       "      <td>14</td>\n",
       "      <td>sales/marketing</td>\n",
       "      <td>3</td>\n",
       "      <td>37922</td>\n",
       "      <td>Federico Fellini</td>\n",
       "      <td>-217123200</td>\n",
       "      <td>Marcello Mastroianni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>[7]</td>\n",
       "      <td>1251</td>\n",
       "      <td>Eight and half</td>\n",
       "      <td>986722200</td>\n",
       "      <td>True</td>\n",
       "      <td>671</td>\n",
       "      <td>17</td>\n",
       "      <td>college/grad student</td>\n",
       "      <td>5</td>\n",
       "      <td>61761</td>\n",
       "      <td>Federico Fellini</td>\n",
       "      <td>-217123200</td>\n",
       "      <td>Marcello Mastroianni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>[7]</td>\n",
       "      <td>1251</td>\n",
       "      <td>Eight and half</td>\n",
       "      <td>960071880</td>\n",
       "      <td>False</td>\n",
       "      <td>5590</td>\n",
       "      <td>12</td>\n",
       "      <td>programmer</td>\n",
       "      <td>2</td>\n",
       "      <td>94117</td>\n",
       "      <td>Federico Fellini</td>\n",
       "      <td>-217123200</td>\n",
       "      <td>Marcello Mastroianni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>[7]</td>\n",
       "      <td>1251</td>\n",
       "      <td>Eight and half</td>\n",
       "      <td>1011993120</td>\n",
       "      <td>True</td>\n",
       "      <td>1851</td>\n",
       "      <td>20</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>5</td>\n",
       "      <td>59602</td>\n",
       "      <td>Federico Fellini</td>\n",
       "      <td>-217123200</td>\n",
       "      <td>Marcello Mastroianni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>[7]</td>\n",
       "      <td>1251</td>\n",
       "      <td>Eight and half</td>\n",
       "      <td>963100320</td>\n",
       "      <td>False</td>\n",
       "      <td>5526</td>\n",
       "      <td>1</td>\n",
       "      <td>artist</td>\n",
       "      <td>5</td>\n",
       "      <td>27514</td>\n",
       "      <td>Federico Fellini</td>\n",
       "      <td>-217123200</td>\n",
       "      <td>Marcello Mastroianni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucketized_user_age movie_genres  movie_id      movie_title   timestamp  \\\n",
       "0                   50          [7]      1251  Eight and half    974089380   \n",
       "1                   18          [7]      1251  Eight and half    986722200   \n",
       "2                   45          [7]      1251  Eight and half    960071880   \n",
       "3                   25          [7]      1251  Eight and half   1011993120   \n",
       "4                   35          [7]      1251  Eight and half    963100320   \n",
       "\n",
       "   user_gender  user_id  user_occupation_label  user_occupation_text  \\\n",
       "0        False     2497                     14       sales/marketing   \n",
       "1         True      671                     17  college/grad student   \n",
       "2        False     5590                     12            programmer   \n",
       "3         True     1851                     20            unemployed   \n",
       "4        False     5526                      1                artist   \n",
       "\n",
       "   user_rating  user_zip_code          director  release_date  \\\n",
       "0            3          37922  Federico Fellini    -217123200   \n",
       "1            5          61761  Federico Fellini    -217123200   \n",
       "2            2          94117  Federico Fellini    -217123200   \n",
       "3            5          59602  Federico Fellini    -217123200   \n",
       "4            5          27514  Federico Fellini    -217123200   \n",
       "\n",
       "                   star  \n",
       "0  Marcello Mastroianni  \n",
       "1  Marcello Mastroianni  \n",
       "2  Marcello Mastroianni  \n",
       "3  Marcello Mastroianni  \n",
       "4  Marcello Mastroianni  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's look at the new features we added: 'movie_imdb_id', 'cast', 'director', 'cast_size', 'crew_size', 'imdb_id' and 'release_date':\n",
    "#Also, please note that all wrong spelled movies are corrected!!!!\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e9c258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7]</td>\n",
       "      <td>1251</td>\n",
       "      <td>Eight and half</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[7]</td>\n",
       "      <td>2188</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7]</td>\n",
       "      <td>1609</td>\n",
       "      <td>One Eight Seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[13, 15]</td>\n",
       "      <td>2311</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>2031</td>\n",
       "      <td>The Million Dollar Duck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_genres  movie_id              movie_title\n",
       "0          [7]      1251          Eight and half \n",
       "1          [7]      2188                       54\n",
       "2          [7]      1609          One Eight Seven\n",
       "3     [13, 15]      2311                     2010\n",
       "4       [3, 4]      2031  The Million Dollar Duck"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's look at the new features we added: 'movie_imdb_id', 'cast', 'director', 'cast_size', 'crew_size', 'imdb_id' and 'release_date':\n",
    "#Also, please note that all wrong spelled movies are corrected!!!!\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3713752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000085 entries, 0 to 1000084\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count    Dtype \n",
      "---  ------                 --------------    ----- \n",
      " 0   bucketized_user_age    1000085 non-null  int64 \n",
      " 1   movie_genres           1000085 non-null  object\n",
      " 2   movie_id               1000085 non-null  int64 \n",
      " 3   movie_title            1000085 non-null  object\n",
      " 4   timestamp              1000085 non-null  int64 \n",
      " 5   user_gender            1000085 non-null  bool  \n",
      " 6   user_id                1000085 non-null  int64 \n",
      " 7   user_occupation_label  1000085 non-null  int64 \n",
      " 8   user_occupation_text   1000085 non-null  object\n",
      " 9   user_rating            1000085 non-null  int64 \n",
      " 10  user_zip_code          1000085 non-null  int64 \n",
      " 11  director               1000085 non-null  object\n",
      " 12  release_date           1000085 non-null  int64 \n",
      " 13  star                   1000085 non-null  object\n",
      "dtypes: bool(1), int64(8), object(5)\n",
      "memory usage: 100.1+ MB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2fe9165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3658 entries, 0 to 3657\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   movie_genres  3658 non-null   object\n",
      " 1   movie_id      3658 non-null   int64 \n",
      " 2   movie_title   3658 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 85.9+ KB\n"
     ]
    }
   ],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20cd6a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_id from int to str:\n",
    "ratings['movie_id'] = ratings['movie_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c8b1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_id from int to str:\n",
    "movies['movie_id'] = movies['movie_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0379b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id from int to str:\n",
    "ratings['user_id'] = ratings['user_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56379ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_zip_code from int to str:\n",
    "ratings['user_zip_code'] = ratings['user_zip_code'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f5e8383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>data_type</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <td>7</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_genres</th>\n",
       "      <td>302</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <td>3656</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_title</th>\n",
       "      <td>3619</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <td>174246</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_gender</th>\n",
       "      <td>2</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>6040</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_occupation_label</th>\n",
       "      <td>21</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_occupation_text</th>\n",
       "      <td>21</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rating</th>\n",
       "      <td>5</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_zip_code</th>\n",
       "      <td>3402</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director</th>\n",
       "      <td>1845</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release_date</th>\n",
       "      <td>2411</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star</th>\n",
       "      <td>1840</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count data_type missing_count missing%\n",
       "bucketized_user_age         7     int64             0      0.0\n",
       "movie_genres              302    object             0      0.0\n",
       "movie_id                 3656    object             0      0.0\n",
       "movie_title              3619    object             0      0.0\n",
       "timestamp              174246     int64             0      0.0\n",
       "user_gender                 2      bool             0      0.0\n",
       "user_id                  6040    object             0      0.0\n",
       "user_occupation_label      21     int64             0      0.0\n",
       "user_occupation_text       21    object             0      0.0\n",
       "user_rating                 5     int64             0      0.0\n",
       "user_zip_code            3402    object             0      0.0\n",
       "director                 1845    object             0      0.0\n",
       "release_date             2411     int64             0      0.0\n",
       "star                     1840    object             0      0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a general view of main_df:\n",
    "ratings_missing = pd.concat([ratings.nunique(), ratings.dtypes, ratings.isnull().sum(), 100*ratings.isnull().mean()], axis=1)\n",
    "ratings_missing.columns = [['count', 'data_type', 'missing_count', 'missing%']]\n",
    "ratings_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6a05ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>data_type</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie_genres</th>\n",
       "      <td>302</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <td>3656</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_title</th>\n",
       "      <td>3619</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count data_type missing_count missing%\n",
       "movie_genres   302    object             0      0.0\n",
       "movie_id      3656    object             0      0.0\n",
       "movie_title   3619    object             0      0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a general view of main_df:\n",
    "movies_missing = pd.concat([movies.nunique(), movies.dtypes, movies.isnull().sum(), 100*movies.isnull().mean()], axis=1)\n",
    "movies_missing.columns = [['count', 'data_type', 'missing_count', 'missing%']]\n",
    "movies_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46d5cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's wrap the **pandas dataframe** into **tf.data.Dataset** object using **tf.data.Dataset.from_tensor_slices** using: tf.data.Dataset.from_tensor_slices\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings))\n",
    "movies = tf.data.Dataset.from_tensor_slices(dict(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ae5062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 50,\n",
      " 'director': b'Federico Fellini',\n",
      " 'movie_genres': b'[7]',\n",
      " 'movie_id': b'1251',\n",
      " 'movie_title': b'Eight and half ',\n",
      " 'release_date': -217123200,\n",
      " 'star': b'Marcello Mastroianni',\n",
      " 'timestamp': 974089380,\n",
      " 'user_gender': False,\n",
      " 'user_id': b'2497',\n",
      " 'user_occupation_label': 14,\n",
      " 'user_occupation_text': b'sales/marketing',\n",
      " 'user_rating': 3,\n",
      " 'user_zip_code': b'37922'}\n"
     ]
    }
   ],
   "source": [
    "#The ratings dataset returns a dictionary of movie id, user id, the assigned rating, timestamp, movie information, and user information:\n",
    "#View the data from ratings dataset:\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c8372ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': b'[7]', 'movie_id': b'1251', 'movie_title': b'Eight and half '}\n"
     ]
    }
   ],
   "source": [
    "#The ratings dataset returns a dictionary of movie id, user id, the assigned rating, timestamp, movie information, and user information:\n",
    "#View the data from ratings dataset:\n",
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13a3633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "})\n",
    "\n",
    "\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f36c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use a random split, putting 75% of the ratings in the train set, and 25% in the test set:\n",
    "# Assign a seed=42 for consistency of results and reproducibility:\n",
    "seed = 42\n",
    "l = len(ratings)\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "shuffled = ratings.shuffle(l, seed=seed, reshuffle_each_iteration=False)\n",
    "\n",
    "#Save 75% of the data for training and 25% for testing:\n",
    "train_ = int(0.75 * l)\n",
    "test_ = int(0.25 * l)\n",
    "\n",
    "train = shuffled.take(train_)\n",
    "test = shuffled.skip(train_).take(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7669611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b' Pret-a-Porter (Ready to Wear)', b\"'night, Mother\",\n",
       "       b'...And God Created Woman (Et Dieu... crea la femme)',\n",
       "       b'...And Justice for All', b'1-900', b'10 Things I Hate About You',\n",
       "       b'101 Dalmatians', b'12 Angry Men', b'2 Days in the Valley',\n",
       "       b'2 or 3 Things I Know About Her'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's find out how many uniques users/movies:\n",
    "movie_titles = movies.batch(l)\n",
    "user_ids = ratings.batch(l).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "#Movies uniques:\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "\n",
    "#users unique\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "# take a look at the movies:\n",
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb239ec9",
   "metadata": {},
   "source": [
    "## 4. A Multi-Task Model\n",
    "\n",
    "There are two critical parts to multi-task recommenders:\n",
    "\n",
    "1. They optimize for two or more objectives, and so have two or more losses.\n",
    "2. They share variables between the tasks, allowing for transfer learning.\n",
    "\n",
    "Now, let's define our models as before, but instead of having  a single task, we will have two tasks: one that predicts ratings, and one that predicts movie watches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39e9252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add 1 to account for the unknown token.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_movie_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5bb57",
   "metadata": {},
   "source": [
    "However, now we will have two tasks. The first is the rating task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19087f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.tasks.ranking.Ranking at 0x2ec33b914c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrs.tasks.Ranking(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba80343",
   "metadata": {},
   "source": [
    "Its goal is to predict the ratings as accurately as possible.\n",
    "\n",
    "The second is the retrieval task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aa8696d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.tasks.retrieval.Retrieval at 0x2ec3ce6a908>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=movies.batch(128)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21411b",
   "metadata": {},
   "source": [
    "As before, this task's goal is to predict which movies the user will or will not watch.\n",
    "\n",
    "**Putting it together**\n",
    "\n",
    "We put it all together in a model class.\n",
    "\n",
    "The new component here is that - since we have two tasks and two losses - we need to decide on how important each loss is. We can do this by giving each of the losses a weight, and treating these weights as hyperparameters. If we assign a large loss weight to the rating task, our model is going to focus on predicting ratings (but still use some information from the retrieval task); if we assign a large loss weight to the retrieval task, it will focus on retrieval instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aabf7c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "    def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "        # We take the loss weights in the constructor: this allows us to instantiate\n",
    "        # several model objects with different loss weights.\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # User and movie models.\n",
    "        self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_movie_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # A small model to take in user and movie embeddings and predict ratings.\n",
    "        # We can make this as complicated as we want as long as we output a scalar\n",
    "        # as our prediction.\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ])\n",
    "\n",
    "        # The tasks.\n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=movies.batch(128).map(self.movie_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # And pick out the movie features and pass them into the movie model.\n",
    "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            # We apply the multi-layered rating model to a concatentation of\n",
    "            # user and movie embeddings.\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        ratings = features.pop(\"user_rating\")\n",
    "\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        # We compute the loss for each task.\n",
    "        rating_loss = self.rating_task(\n",
    "                                      labels=ratings,\n",
    "                                      predictions=rating_predictions,\n",
    "                                      )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "        # And combine them using the loss weights.\n",
    "        return (self.rating_weight * rating_loss\n",
    "                + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df50e15",
   "metadata": {},
   "source": [
    "### 4.1 Rating-specialized model\n",
    "\n",
    "Depending on the weights we assign, the model will encode a different balance of the tasks. Let's start with a model that only considers ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d84ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=0.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98c926f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then shuffle, batch, and cache the training and evaluation data:\n",
    "# Segment the batches so that the model runs 13 training batches (2^13) and 11 test batches (2^11) per epoch, \n",
    "# while having a batch size which is a multiple of 2^n.\n",
    "cached_train = train.shuffle(l).batch(8192).cache()\n",
    "cached_test = test.batch(2048).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ced7f138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\aktha\\anaconda3\\envs\\tfrs\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "92/92 [==============================] - 257s 3s/step - root_mean_squared_error: 1.2577 - factorized_top_k/top_1_categorical_accuracy: 1.8798e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0014 - factorized_top_k/top_10_categorical_accuracy: 0.0029 - factorized_top_k/top_50_categorical_accuracy: 0.0145 - factorized_top_k/top_100_categorical_accuracy: 0.0284 - loss: 1.5751 - regularization_loss: 0.0000e+00 - total_loss: 1.5751\n",
      "Epoch 2/3\n",
      "92/92 [==============================] - 218s 2s/step - root_mean_squared_error: 1.0390 - factorized_top_k/top_1_categorical_accuracy: 2.7864e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0020 - factorized_top_k/top_10_categorical_accuracy: 0.0039 - factorized_top_k/top_50_categorical_accuracy: 0.0174 - factorized_top_k/top_100_categorical_accuracy: 0.0328 - loss: 1.0783 - regularization_loss: 0.0000e+00 - total_loss: 1.0783\n",
      "Epoch 3/3\n",
      "92/92 [==============================] - 273s 3s/step - root_mean_squared_error: 0.9674 - factorized_top_k/top_1_categorical_accuracy: 2.5731e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0017 - factorized_top_k/top_10_categorical_accuracy: 0.0035 - factorized_top_k/top_50_categorical_accuracy: 0.0166 - factorized_top_k/top_100_categorical_accuracy: 0.0318 - loss: 0.9350 - regularization_loss: 0.0000e+00 - total_loss: 0.9350\n",
      "123/123 [==============================] - 139s 806ms/step - root_mean_squared_error: 0.9403 - factorized_top_k/top_1_categorical_accuracy: 2.6398e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0017 - factorized_top_k/top_10_categorical_accuracy: 0.0035 - factorized_top_k/top_50_categorical_accuracy: 0.0161 - factorized_top_k/top_100_categorical_accuracy: 0.0308 - loss: 0.8847 - regularization_loss: 0.0000e+00 - total_loss: 0.8847\n",
      "Retrieval top-100 accuracy: 0.031.\n",
      "Ranking RMSE: 0.940.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81512952",
   "metadata": {},
   "source": [
    "Alright, here we get good RMSE but with poor prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba2619b",
   "metadata": {},
   "source": [
    "### 4.2 Retrieval-specialized model\n",
    "\n",
    "Let's now try a model that focuses on retrieval only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08b058c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=0.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e25ab30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "92/92 [==============================] - 291s 3s/step - root_mean_squared_error: 3.8135 - factorized_top_k/top_1_categorical_accuracy: 7.5994e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0072 - factorized_top_k/top_10_categorical_accuracy: 0.0155 - factorized_top_k/top_50_categorical_accuracy: 0.0745 - factorized_top_k/top_100_categorical_accuracy: 0.1346 - loss: 71210.2944 - regularization_loss: 0.0000e+00 - total_loss: 71210.2944\n",
      "Epoch 2/3\n",
      "92/92 [==============================] - 301s 3s/step - root_mean_squared_error: 3.8523 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0126 - factorized_top_k/top_10_categorical_accuracy: 0.0257 - factorized_top_k/top_50_categorical_accuracy: 0.1083 - factorized_top_k/top_100_categorical_accuracy: 0.1860 - loss: 68970.8301 - regularization_loss: 0.0000e+00 - total_loss: 68970.8301\n",
      "Epoch 3/3\n",
      "92/92 [==============================] - 298s 3s/step - root_mean_squared_error: 3.8641 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0145 - factorized_top_k/top_10_categorical_accuracy: 0.0290 - factorized_top_k/top_50_categorical_accuracy: 0.1171 - factorized_top_k/top_100_categorical_accuracy: 0.1971 - loss: 68264.1524 - regularization_loss: 0.0000e+00 - total_loss: 68264.1524\n",
      "123/123 [==============================] - 101s 802ms/step - root_mean_squared_error: 3.8684 - factorized_top_k/top_1_categorical_accuracy: 9.7992e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0083 - factorized_top_k/top_10_categorical_accuracy: 0.0179 - factorized_top_k/top_50_categorical_accuracy: 0.0866 - factorized_top_k/top_100_categorical_accuracy: 0.1576 - loss: 14396.0634 - regularization_loss: 0.0000e+00 - total_loss: 14396.0634\n",
      "Retrieval top-100 accuracy: 0.158.\n",
      "Ranking RMSE: 3.868.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6310c5",
   "metadata": {},
   "source": [
    "Interesting, now we're getting the opposite results, poor RMSE but with better predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91870efe",
   "metadata": {},
   "source": [
    "### 4.3  Joint model\n",
    "\n",
    "Let's now train a model that assigns positive weights to both tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9113215",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da20162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "92/92 [==============================] - 302s 3s/step - root_mean_squared_error: 1.2950 - factorized_top_k/top_1_categorical_accuracy: 6.7328e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0067 - factorized_top_k/top_10_categorical_accuracy: 0.0147 - factorized_top_k/top_50_categorical_accuracy: 0.0712 - factorized_top_k/top_100_categorical_accuracy: 0.1286 - loss: 71276.6060 - regularization_loss: 0.0000e+00 - total_loss: 71276.6060\n",
      "Epoch 2/3\n",
      "92/92 [==============================] - 293s 3s/step - root_mean_squared_error: 1.0012 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0125 - factorized_top_k/top_10_categorical_accuracy: 0.0253 - factorized_top_k/top_50_categorical_accuracy: 0.1076 - factorized_top_k/top_100_categorical_accuracy: 0.1847 - loss: 69020.9598 - regularization_loss: 0.0000e+00 - total_loss: 69020.9598\n",
      "Epoch 3/3\n",
      "92/92 [==============================] - 291s 3s/step - root_mean_squared_error: 0.9939 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0142 - factorized_top_k/top_10_categorical_accuracy: 0.0287 - factorized_top_k/top_50_categorical_accuracy: 0.1170 - factorized_top_k/top_100_categorical_accuracy: 0.1969 - loss: 68288.8273 - regularization_loss: 0.0000e+00 - total_loss: 68288.8273\n",
      "123/123 [==============================] - 91s 718ms/step - root_mean_squared_error: 0.9739 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0082 - factorized_top_k/top_10_categorical_accuracy: 0.0176 - factorized_top_k/top_50_categorical_accuracy: 0.0864 - factorized_top_k/top_100_categorical_accuracy: 0.1578 - loss: 14400.7003 - regularization_loss: 0.0000e+00 - total_loss: 14400.7003\n",
      "Retrieval top-100 accuracy: 0.158.\n",
      "Ranking RMSE: 0.974.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec21436",
   "metadata": {},
   "source": [
    "Better, over all results compared to the previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc34da",
   "metadata": {},
   "source": [
    "## 5. Modeling Summary\n",
    "\n",
    "Alright, as shown below joint model managed to provide both better prediction with low RMSE, as shown below:\n",
    "\n",
    " |Models|Retrieval top-100 accuracy | Ranking RMSE|\n",
    " |:--:|:--:|:--:|\n",
    "  |Model 1: Rating-specialized model|0.031|0.940|\n",
    " |Model 2: Retrieval-specialized model|0.158|3.868|\n",
    " |Model 3: Joint model|0.158|0.974|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a83565",
   "metadata": {},
   "source": [
    "## 6. Next Step - Joint Model Tuning\n",
    "\n",
    "Alright, let's focus in tuning the joint model due to the high potential, so, we'll do the following: \n",
    "\n",
    " * Adding more features\n",
    " * Optimize Embedding\n",
    " * embedding_dimension 32 to 64\n",
    " * epochs= 3 to 32\n",
    " * Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e10284b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfrs] *",
   "language": "python",
   "name": "conda-env-tfrs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
